{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a655c6-0e23-473d-bec2-9a330a52209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RR by Year:\n",
      "2002: 0.4113\n",
      "2003: 0.5413\n",
      "2004: 0.5135\n",
      "2005: 0.6152\n",
      "2006: 0.7162\n",
      "2007: 0.7054\n",
      "2008: 0.7395\n",
      "2009: 0.7126\n",
      "2010: 0.5851\n",
      "2011: 0.6259\n",
      "\n",
      "Mean Coefficient of Recovery:\n",
      "0.02179563\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Write a program designed to read a DEM and calculate slope and aspect then reclassify based off of 8 cardinal directions and reclassify the slope grid into 10 classes using provided functin\n",
    "\n",
    "Calculate the NDVI for all years of analysis\n",
    "\n",
    "Calculate recovery ratio for each pixel for each year\n",
    "\n",
    "Calculate the trend of the recovery ratio across the years of analysis\n",
    "\n",
    "Display the recovery ratio and display the coefficient of recovery\n",
    "\n",
    "Part Two will generate a function that calculates zonal statistics as a table using two numpy arrays\n",
    "\n",
    "Calculate zonal stats of the coefficient of recovery for each terrain slope class and cardinal direction, produce two output csvs\n",
    "\n",
    "export final coefficent of recovery as a np array for the burned area as a geotiff with non-burned pixels having a nodata value\n",
    "\n",
    "display conclusions regarding vegetation recovery and terrain\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from math import pi\n",
    "\n",
    "#create global constants\n",
    "\n",
    "cell_size = 30\n",
    "fire_perimeter_path ='data/data/fire_perimeter.tif'\n",
    "dem_path ='data/data/bigElk_dem.tif'\n",
    "bands_path = 'data/data/L5_big_elk'\n",
    "\n",
    "years = list(range(2002,2012))\n",
    "nodata = -99\n",
    "\n",
    "#Function to calculate slope and aspect\n",
    "\n",
    "def slopeAspect(dem,cs):\n",
    "    kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    dzdx = ndimage.convolve(dem, kernel, mode='mirror') / (8 * cs)\n",
    "    dzdy = ndimage.convolve(dem, kernel.T, mode='mirror') / (8 * cs)\n",
    "    slp = np.arctan((dzdx ** 2 + dzdy ** 2) ** 0.5) * 180 / pi\n",
    "    ang = np.arctan2(-dzdy, dzdx) * 180 / pi\n",
    "    aspect = np.where(ang > 90, 450 - ang, 90 - ang)\n",
    "    return slp, aspect\n",
    "\n",
    "#function to reclassify aspect to cardinal directions\n",
    "\n",
    "def reclassAspect(npArray):\n",
    "    return np.where((npArray > 22.5) & (npArray <= 67.5), 2,\n",
    "    np.where((npArray > 67.5) & (npArray <= 112.5), 3,\n",
    "    np.where((npArray > 112.5) & (npArray <= 157.5), 4,\n",
    "    np.where((npArray > 157.5) & (npArray <= 202.5), 5,\n",
    "    np.where((npArray > 202.5) & (npArray <= 247.5), 6,\n",
    "    np.where((npArray > 247.5) & (npArray <= 292.5), 7,\n",
    "    np.where((npArray > 292.5) & (npArray <= 337.5), 8, 1)))))))\n",
    "\n",
    "#function to reclassify array into bins\n",
    "\n",
    "def reclassByHisto(npArray, bins):\n",
    "    array = np.where(np.isnan(npArray), 0, npArray)\n",
    "    histo = np.histogram(array, bins)[1]\n",
    "    rClss = np.zeros_like(npArray)\n",
    "    for i in range(bins):\n",
    "        rClss = np.where((npArray >= histo[i]) & (npArray <= histo[i + 1]), i + 1, rClss)\n",
    "    return rClss\n",
    "\n",
    "#Read dem and find slope/aspect\n",
    "dem = rasterio.open(dem_path).read(1).astype('float32')\n",
    "slope, aspect = slopeAspect(dem, cell_size)\n",
    "aspect_class = reclassAspect(aspect)\n",
    "slope_class = reclassByHisto(slope, bins=10)\n",
    "\n",
    "#read fire perimeter as mask\n",
    "fire_mask = rasterio.open(fire_perimeter_path)\n",
    "fire_array = fire_mask.read(1)\n",
    "burned = fire_array == 1\n",
    "healthy = fire_array == 2\n",
    "\n",
    "\n",
    "#create empty lists to store ndvi and rr\n",
    "\n",
    "\n",
    "ndvi_list = []\n",
    "\n",
    "rr_list = []\n",
    "\n",
    "#iterate through landsat imagery and append to ndvi and rr\n",
    "\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    b3_pattern = os.path.join(bands_path, f\"L5*{year}*B3.tif\")\n",
    "    b4_pattern = os.path.join(bands_path, f\"L5*{year}*B4.tif\")\n",
    "    \n",
    "    b3_matches = glob(b3_pattern)\n",
    "    b4_matches = glob(b4_pattern)\n",
    "\n",
    "    if not b3_matches or not b4_matches:\n",
    "        print(f\"Warning: Missing data for year {year}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    red = rasterio.open(b3_matches[0]).read(1).astype(\"float32\")\n",
    "    nir = rasterio.open(b4_matches[0]).read(1).astype(\"float32\")\n",
    "    ndvi = (nir - red) / (nir + red + 1e-10)\n",
    "    ndvi_list.append(ndvi)\n",
    "\n",
    "    healthy_ndvi_mean = np.nanmean(ndvi[healthy])\n",
    "    rr = np.where(burned, ndvi / healthy_ndvi_mean, np.nan)\n",
    "    rr_list.append(rr)\n",
    "\n",
    "\n",
    "#find coefficient of recovery\n",
    "\n",
    "rr_array = np.array(rr_list)\n",
    "coeff_recovery = np.full_like(rr_array[0], np.nan)\n",
    "\n",
    "for i in range(rr_array.shape[1]):\n",
    "    for j in range(rr_array.shape[2]):\n",
    "        if burned[i, j]:\n",
    "            y = rr_array[:, i, j]\n",
    "            if not np.any(np.isnan(y)):\n",
    "                slope_val, _ = np.polyfit(years, y, 1)\n",
    "                coeff_recovery[i, j] = slope_val\n",
    "\n",
    "#display results\n",
    "print(\"Mean RR by Year:\")\n",
    "for i, year in enumerate(years):\n",
    "    print(f\"{year}: {np.nanmean(rr_array[i][burned]):.4f}\")\n",
    "\n",
    "print(\"\\nMean Coefficient of Recovery:\")\n",
    "print(np.nanmean(coeff_recovery[burned]))\n",
    "\n",
    "\n",
    "#Part two, zonal statistics\n",
    "\n",
    "#define function to create zonal stats table\n",
    "\n",
    "def zonal_stats_table(zones, values):\n",
    "    df = pd.DataFrame({'zone': zones.flatten(), 'value': values.flatten()})\n",
    "    df = df.dropna()\n",
    "    grouped = df.groupby('zone')['value']\n",
    "    stats = grouped.agg(['min', 'max', 'mean', 'std', 'count']).reset_index()\n",
    "    return stats\n",
    "\n",
    "#apply zonal stats to only burned areas\n",
    "\n",
    "masked_coeff = np.where(burned, coeff_recovery, np.nan)\n",
    "\n",
    "#calculate slope zonal stats and export as csv\n",
    "\n",
    "slope_stats = zonal_stats_table(slope_class, masked_coeff)\n",
    "slope_stats.to_csv(\"slope_zonal_stats.csv\", index=False)\n",
    "\n",
    "#calculate aspect zonal stats and export as csv\n",
    "\n",
    "aspect_stats = zonal_stats_table(aspect_class, masked_coeff)\n",
    "aspect_stats.to_csv(\"aspect_zonal_stats.csv\", index=False)\n",
    "\n",
    "#export geotiff of final coefficient of recovery\n",
    "\n",
    "profile = fire_mask.profile\n",
    "profile.update(dtype=rasterio.float32, count=1, nodata=nodata)\n",
    "\n",
    "out_arr = np.where(burned, coeff_recovery, nodata).astype(np.float32)\n",
    "\n",
    "with rasterio.open(\"coeff_recovery.tif\", \"w\", **profile) as dst:\n",
    "    dst.write(out_arr, 1)\n",
    "\n",
    "\n",
    "\n",
    "#display conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe474175-602b-4260-b65e-0b69dd8d4acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion Values:\n",
      "Max slope class: 2, mean recovery: 0.0260\n",
      "Min slope class: 10, mean recovery: 0.0117\n",
      "Max aspect class: 8 (Northwest), mean recovery: 0.0338\n",
      "Min aspect class: 4 (Southeast), mean recovery: 0.0141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the zonal stats CSVs\n",
    "slope_stats = pd.read_csv(\"slope_zonal_stats.csv\")\n",
    "aspect_stats = pd.read_csv(\"aspect_zonal_stats.csv\")\n",
    "\n",
    "\n",
    "aspect_labels = {\n",
    "    1: \"North\",\n",
    "    2: \"Northeast\",\n",
    "    3: \"East\",\n",
    "    4: \"Southeast\",\n",
    "    5: \"South\",\n",
    "    6: \"Southwest\",\n",
    "    7: \"West\",\n",
    "    8: \"Northwest\"\n",
    "}\n",
    "\n",
    "# Find slope stats\n",
    "max_slope = slope_stats.loc[slope_stats['mean'].idxmax()]\n",
    "min_slope = slope_stats.loc[slope_stats['mean'].idxmin()]\n",
    "\n",
    "# Find aspect stats\n",
    "max_aspect = aspect_stats.loc[aspect_stats['mean'].idxmax()]\n",
    "min_aspect = aspect_stats.loc[aspect_stats['mean'].idxmin()]\n",
    "\n",
    "# Aspect names\n",
    "max_aspect_name = aspect_labels.get(int(max_aspect['zone']), \"Unknown\")\n",
    "min_aspect_name = aspect_labels.get(int(min_aspect['zone']), \"Unknown\")\n",
    "\n",
    "# Print detailed conclusion\n",
    "print(\"\\nConclusion Values:\")\n",
    "print(f\"Max slope class: {int(max_slope['zone'])}, mean recovery: {max_slope['mean']:.4f}\")\n",
    "print(f\"Min slope class: {int(min_slope['zone'])}, mean recovery: {min_slope['mean']:.4f}\")\n",
    "print(f\"Max aspect class: {int(max_aspect['zone'])} ({max_aspect_name}), mean recovery: {max_aspect['mean']:.4f}\")\n",
    "print(f\"Min aspect class: {int(min_aspect['zone'])} ({min_aspect_name}), mean recovery: {min_aspect['mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f314337d-48b8-4006-b872-ed2e6767c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion:\n",
      "Vegetation recovery after the Big Elk wildfire varied by terrain characteristics. Recovery was pronounced\n",
      "on moderate slopes (slope class 2) and declined slightly on the steepest terrain (slope class 10), suggesting\n",
      "that gentle to moderate slopes may support better conditions for post-fire regrowth. In terms of aspect,\n",
      "Northwest-facing slopes (class 8) exhibited the highest recovery rates, while Southeast-facing slopes (class 4)\n",
      "had the lowest. This pattern indicates that moisture and reduced sun exposure on northwest aspects may\n",
      "promote more vegetation regrowth following fire disturbances.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConclusion:\")\n",
    "print(\"Vegetation recovery after the Big Elk wildfire varied by terrain characteristics. Recovery was pronounced\")\n",
    "print(\"on moderate slopes (slope class 2) and declined slightly on the steepest terrain (slope class 10), suggesting\")\n",
    "print(\"that gentle to moderate slopes may support better conditions for post-fire regrowth. In terms of aspect,\")\n",
    "print(\"Northwest-facing slopes (class 8) exhibited the highest recovery rates, while Southeast-facing slopes (class 4)\")\n",
    "print(\"had the lowest. This pattern indicates that moisture and reduced sun exposure on northwest aspects may\")\n",
    "print(\"promote more vegetation regrowth following fire disturbances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2babe4-57b4-45c5-be61-3eaa7e95be37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
